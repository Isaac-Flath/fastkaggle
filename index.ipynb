{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastkaggle.core import *\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fastkaggle\n",
    "\n",
    "> Kaggling for fast kagglers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either:\n",
    "\n",
    "    pip install fastkaggle\n",
    "\n",
    "or:\n",
    "\n",
    "    mamba install -c fastai fastkaggle\n",
    "\n",
    "(or replace `mamba` with `conda` if you don't mind it taking much longer to run...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This little library is where I'll be putting snippets of stuff which are useful on Kaggle. Functionality includes the following:\n",
    "\n",
    "It defines `iskaggle` which is `True` if you're running on Kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Not Kaggle'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Kaggle' if iskaggle else 'Not Kaggle'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It provides a `setup_comp` function which gets a path to the data for a competition, downloading it if needed, and also installs any modules that might be missing or out of data if running on Kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('titanic')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setup_comp('titanic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's also `push_notebook` to push a notebook to Kaggle Notebooks, and `import_kaggle` to use the Kaggle API (even when you're on Kaggle!) See the `fastkaggle.core` docs for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is designed to make uploading pip libraries to kaggle datasets easy.  There's 2 primary high level functions to be used.  First we can define our kaggle username and the local path we want to use to store datasets when we create them. \n",
    "\n",
    ":::{.callout-tip}\n",
    "## Usage tip\n",
    "The purpose of this is to create datasets that can be used in no internet inference competitions to install libraries using `pip install -Uqq library --no-index --find-links=file:///kaggle/input/your_dataset/`\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_path = Path('/root/kaggle_datasets')\n",
    "username = 'isaacflath'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of Libraries\n",
    "\n",
    "We can take a list of libraries and upload them as seperate datasets.  For example the below will create a `library-fastcore` and `library-timm` dataset.  If they already exist, it will push a new version if there is a more recent version available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fastcore as library-fastcore at /root/kaggle_datasets/library-fastcore\n",
      "-----Downloading or Creating Dataset\n",
      "-----Checking dataset version against pip\n",
      "-----Kaggle dataset already up to date 1.5.16 to 1.5.16\n",
      "Processing timm as library-timm at /root/kaggle_datasets/library-timm\n",
      "-----Downloading or Creating Dataset\n",
      "-----Checking dataset version against pip\n",
      "-----Kaggle dataset already up to date 0.6.7 to 0.6.7\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "libs = ['fastcore','timm']\n",
    "create_libs_datasets(libs,lib_path,username)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creats datasets in kaggle with the needed files.  For example the library `fastkaggle` looks like this in kaggle.\n",
    "\n",
    "![Fastkaggle Dataset](images/library-fastkaggle.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### requirements.txt \n",
    "\n",
    "We can also create a singular dataset with multiple libraries based on a `requirements.txt` file for the project.  If there are any different files it will push a new version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing libraries-pawpularity at /root/kaggle_datasets/libraries-pawpularity\n",
      "-----Downloading or Creating Dataset\n",
      "Data package template written to: /root/kaggle_datasets/libraries-pawpularity/dataset-metadata.json\n",
      "-----Checking dataset version against pip\n",
      "-----Updating libraries-pawpularity in Kaggle\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "create_requirements_dataset('test_files/requirements.txt',lib_path,'libraries-pawpularity', username)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a dataset in kaggle with the needed files.\n",
    "\n",
    "![Pawpularity Dataset](images/libraries-pawpularity.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
