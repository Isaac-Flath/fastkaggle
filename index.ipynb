{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastkaggle.core import *\n",
    "from fastkaggle.competition import *\n",
    "from fastkaggle.datasets import *\n",
    "from fastkaggle.libraries import *\n",
    "from fastkaggle.models import *\n",
    "from fastkaggle.notebooks import *\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fastkaggle\n",
    "\n",
    "> Kaggling for fast kagglers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either:\n",
    "\n",
    "    pip install fastkaggle\n",
    "\n",
    "or:\n",
    "\n",
    "    mamba install -c fastai fastkaggle\n",
    "\n",
    "(or replace `mamba` with `conda` if you don't mind it taking much longer to run...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This little library is where I'll be putting snippets of stuff which are useful on Kaggle. Functionality includes the following:\n",
    "\n",
    "It defines `iskaggle` which is `True` if you're running on Kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Not Kaggle'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Kaggle' if iskaggle else 'Not Kaggle'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the kaggle api directly, even on kaggle with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = import_kaggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The competition module gives a `setup_comp` function which:\n",
    "1. Gets a path to the data for a competition, downloading it if needed\n",
    "1. installs any modules that might be missing or out of data if running on Kaggle\n",
    "1. Creates a config file with the competition name, paths where datasets to be stored, username to use for datasets, and other competition configurable items\n",
    "\n",
    ">Note:  All config values have smart defaults that work for almost every competition.  You don't have to define any of them, but you're welcome to change them if you'd like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferring dataset_username from credentials\n",
      "Inferring model_dataset_name from competition\n",
      "Inferring libraries_dataset_name from competition\n",
      "Setting required libraries to ['fastkaggle']\n"
     ]
    }
   ],
   "source": [
    "setup_comp('titanic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "\n",
    "The Libraries module gives a function to manage pip libraries as kaggle datasets, especially useful for no-internet inference competitions\n",
    "\n",
    "Simply define list your pip requirements in the `fastkaggle.json` config file and call `create_dependency_dataset` anytime for it to create/update the dataset with the lastest of those packages in pip.\n",
    "\n",
    ":::{.callout-tip}\n",
    "## Usage tip\n",
    "The purpose of this is to create datasets that can be used in no internet inference competitions to install libraries using `pip install -Uqq library --no-index --find-links=file:///kaggle/input/your_dataset/`\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Downloading or Creating Dataset if needed\n",
      "-----Checking dataset files against pip\n",
      "-----Kaggle dataset already up to date\n"
     ]
    }
   ],
   "source": [
    "create_dependency_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models\n",
    "\n",
    "The Models module gives functions to manage your models as kaggle datasets, especially useful for no-internet inference competitions\n",
    "\n",
    "Simply create and train your normal fastai model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:51] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "# create fastai model\n",
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "df = pd.read_csv(path/'labels.csv')\n",
    "dls = ImageDataLoaders.from_df(df,path)\n",
    "learn = vision_learner(dls, models.resnet18, loss_func=CrossEntropyLossFlat(), ps=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then pass is to `fastkaggle` with a name a version comment for it to be exported and updated in your competition kaggle dataset (defined in `fastkaggle.json` config file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Downloading or Creating Dataset if needed\n",
      "models-titanic\n"
     ]
    }
   ],
   "source": [
    "push_fastai_learner(learn,'model1.pkl','testing fastkaggle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebooks can be pushed to kaggle kernels with `push_notebook`, and these notebooks can understand if they are running locally or in kaggle thanks to `is_kaggle`.  No need to manage 2 environments, just work on your own machine and push anytime!\n",
    "\n",
    "This function:\n",
    "+ Infers title using nbdev\n",
    "+ Creates Id by removing punctuation, whitespace and lowecasing title\n",
    "+ Links you kaggle dataset with your libraries and your kaggle dataset with your models to it as defined in `fastkaggle.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel version 18 successfully pushed.  Please check progress at https://www.kaggle.com/code/isaacflath/fastkaggle\n"
     ]
    }
   ],
   "source": [
    "push_notebook('index.ipynb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
