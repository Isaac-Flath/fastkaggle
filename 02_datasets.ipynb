{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fastkaggle.datasets\n",
    "\n",
    "> API details for fastkaggle mid level datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import os,json,subprocess, shutil\n",
    "import re\n",
    "from pathlib import Path\n",
    "from fastcore.utils import *\n",
    "from fastkaggle.core import *\n",
    "from fastkaggle.competition import *\n",
    "# from fastcore.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def ds_exists(dataset_slug, # Dataset slug (ie \"zillow/zecon\")\n",
    "                   path='.'):\n",
    "    md_path = Path(Path(path)/'dataset-metadata.json')\n",
    "    assert not md_path.exists(),'dataset-metadata.json already exists. Use a path that is not a kaggle dataset'\n",
    "    try: \n",
    "        api=import_kaggle()\n",
    "        api.dataset_metadata(dataset_slug,path)\n",
    "        md_path.unlink()\n",
    "        return True\n",
    "    except Exception as ex:\n",
    "        if '404' in str(ex): return False\n",
    "        else: raise ex  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ds_exists('isaacflath/library-fastkaggle')\n",
    "assert not ds_exists('not/real/dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'competition': 'titanic',\n",
       " 'pip_cmd': 'pip',\n",
       " 'data_path': '.',\n",
       " 'datasets_username': 'isaacflath',\n",
       " 'model_dataset_name': 'models-titanic',\n",
       " 'libraries_dataset_name': 'libraries-titanic',\n",
       " 'required_libraries': ['fastkaggle']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = get_config_values()\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def mk_dataset(dataset_path, # Local path to create dataset in\n",
    "               title, # Name of the dataset\n",
    "               force=False, # Should it overwrite or error if exists?\n",
    "               upload=True # Should it upload and create on kaggle\n",
    "              ):\n",
    "    '''Creates minimal dataset metadata needed to push new dataset to kaggle'''\n",
    "    cfg = get_config_values()\n",
    "    dataset_path = Path(dataset_path)\n",
    "    dataset_path.mkdir(exist_ok=force,parents=True)\n",
    "    api = import_kaggle()\n",
    "    api.dataset_initialize(dataset_path)\n",
    "    md = json.load(open(dataset_path/'dataset-metadata.json'))\n",
    "    md['title'] = title\n",
    "    md['id'] = md['id'].replace('INSERT_SLUG_HERE',title)\n",
    "    json.dump(md,open(dataset_path/'dataset-metadata.json','w'))\n",
    "    if upload: (dataset_path/'empty.txt').touch()\n",
    "    api.dataset_create_new(str(dataset_path),public=True,dir_mode='zip',quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data package template written to: testds/dataset-metadata.json\n"
     ]
    }
   ],
   "source": [
    "mk_dataset('./testds','mytestds',force=True,upload=False)\n",
    "\n",
    "path = Path('./testds/dataset-metadata.json')\n",
    "md = json.load(open(path))\n",
    "assert md['title'] == 'mytestds'\n",
    "assert md['id'].endswith('/mytestds')\n",
    "\n",
    "path.unlink()\n",
    "path.parent.rmdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_dataset(dataset_slug, # Dataset slug (ie \"zillow/zecon\")\n",
    "                dataset_path, # Local path to download dataset to\n",
    "                unzip=True, # Should it unzip after downloading?\n",
    "                force=False # Should it overwrite or error if dataset_path exists?\n",
    "               ):\n",
    "    '''Downloads an existing dataset and metadata from kaggle'''\n",
    "    if not force: assert not Path(dataset_path).exists()\n",
    "    api = import_kaggle()\n",
    "    api.dataset_metadata(dataset_slug,str(dataset_path))\n",
    "    api.dataset_download_files(dataset_slug,str(dataset_path))\n",
    "    if unzip:\n",
    "        zipped_file = Path(dataset_path)/f\"{dataset_slug.split('/')[-1]}.zip\"\n",
    "        import zipfile\n",
    "        with zipfile.ZipFile(zipped_file, 'r') as zip_ref:\n",
    "            zip_ref.extractall(Path(dataset_path))\n",
    "        zipped_file.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path('./data-science-job-salaries')\n",
    "get_dataset('ruchi798/data-science-job-salaries',dataset_path)\n",
    "\n",
    "files = os.listdir(dataset_path)\n",
    "files.sort()\n",
    "\n",
    "assert files == ['dataset-metadata.json', 'ds_salaries.csv']\n",
    "\n",
    "for f in Path(dataset_path).ls(): f.unlink()\n",
    "Path(dataset_path).rmdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def push_dataset(dataset_path, # Local path where dataset is stored \n",
    "                 version_comment, # Comment associated with this dataset update\n",
    "                quiet=True\n",
    "                ):\n",
    "    '''Push dataset update to kaggle.  Dataset path must contain dataset metadata file'''\n",
    "    api = import_kaggle()\n",
    "    api.dataset_create_version(str(dataset_path),version_comment,dir_mode='zip',quiet=quiet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
