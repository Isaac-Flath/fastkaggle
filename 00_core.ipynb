{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fastkaggle.core\n",
    "\n",
    "> API details for fastkaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import os,json,subprocess\n",
    "from fastcore.utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def import_kaggle():\n",
    "    \"Import kaggle API, using Kaggle secrets `kaggle_username` and `kaggle_key` if needed\"\n",
    "    if iskaggle:\n",
    "        from kaggle_secrets import UserSecretsClient\n",
    "        sec = UserSecretsClient()\n",
    "        os.environ['KAGGLE_USERNAME'] = sec.get_secret(\"kaggle_username\")\n",
    "        if not os.environ['KAGGLE_USERNAME']: raise Exception(\"Please insert your Kaggle username and key into Kaggle secrets\")\n",
    "        os.environ['KAGGLE_KEY'] = sec.get_secret(\"kaggle_key\")\n",
    "    from kaggle import api\n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#20) [contradictory-my-dear-watson,gan-getting-started,store-sales-time-series-forecasting,tpu-getting-started,digit-recognizer,titanic,house-prices-advanced-regression-techniques,connectx,nlp-getting-started,spaceship-titanic...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api = import_kaggle()\n",
    "L(api.competitions_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def setup_comp(competition, install=''):\n",
    "    \"Get a path to data for `competition`, downloading it if needed\"\n",
    "    if iskaggle:\n",
    "        if install:\n",
    "            os.system(f'pip install -Uqq {install}')\n",
    "        return Path('../input')/competition\n",
    "    else:\n",
    "        path = Path(competition)\n",
    "        from kaggle import api\n",
    "        if not path.exists():\n",
    "            import zipfile\n",
    "            api.competition_download_cli(str(competition))\n",
    "            zipfile.ZipFile(f'{competition}.zip').extractall(str(competition))\n",
    "        return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading titanic.zip to /notebooks/github/fastkaggle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34.1k/34.1k [00:00<00:00, 12.9MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Path('titanic')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setup_comp('titanic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you pass a list of space separated modules to `install`, they'll be installed if running on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def nb_meta(user, id, title, file, competition=None, private=True, gpu=False, internet=True):\n",
    "    \"Get the `dict` required for a kernel-metadata.json file\"\n",
    "    d = {\n",
    "      \"id\": f\"{user}/{id}\",\n",
    "      \"title\": title,\n",
    "      \"code_file\": file,\n",
    "      \"language\": \"python\",\n",
    "      \"kernel_type\": \"notebook\",\n",
    "      \"is_private\": private,\n",
    "      \"enable_gpu\": gpu,\n",
    "      \"enable_internet\": internet,\n",
    "      \"keywords\": [],\n",
    "      \"dataset_sources\": [],\n",
    "      \"kernel_sources\": []\n",
    "    }\n",
    "    if competition: d[\"competition_sources\"] = [f\"competitions/{competition}\"]\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'jhoward/my-notebook',\n",
       " 'title': 'My notebook',\n",
       " 'code_file': 'my-notebook.ipynb',\n",
       " 'language': 'python',\n",
       " 'kernel_type': 'notebook',\n",
       " 'is_private': True,\n",
       " 'enable_gpu': False,\n",
       " 'enable_internet': True,\n",
       " 'keywords': [],\n",
       " 'dataset_sources': [],\n",
       " 'kernel_sources': [],\n",
       " 'competition_sources': ['competitions/paddy-disease-classification']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_meta('jhoward', 'my-notebook', 'My notebook', 'my-notebook.ipynb', competition='paddy-disease-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def push_notebook(user, id, title, file, path='.', competition=None, private=True, gpu=False, internet=True):\n",
    "    \"Push notebook `file` to Kaggle Notebooks\"\n",
    "    meta = nb_meta(user, id, title, file=file, competition=competition, private=private, gpu=gpu, internet=internet)\n",
    "    path = Path(path)\n",
    "    nm = 'kernel-metadata.json'\n",
    "    path.mkdir(exist_ok=True, parents=True)\n",
    "    with open(path/nm, 'w') as f: json.dump(meta, f, indent=2)\n",
    "    from kaggle import api\n",
    "    api.kernels_push_cli(str(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Kaggle recommends that the `id` match the *slug* for the title -- i.e it should be the same as the title, but lowercase, no punctuation, and spaces replaced with dashes. E.g:\n",
    "\n",
    "```python\n",
    "push_notebook('jhoward', 'first-steps-road-to-the-top-part-1',\n",
    "              title='First Steps: Road to the Top, Part 1',\n",
    "              file='first-steps-road-to-the-top-part-1.ipynb',\n",
    "              competition='paddy-disease-classification',\n",
    "              private=False, gpu=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def mk_dataset(dataset_path, # Local path to create dataset in\n",
    "               title, # Name of the dataset\n",
    "               force=False, # Should it overwrite or error if exists?\n",
    "               upload=True # Should it upload and create on kaggle\n",
    "              ):\n",
    "    '''Creates minimal dataset metadata needed to push new dataset to kaggle'''\n",
    "    dataset_path = Path(dataset_path)\n",
    "    dataset_path.mkdir(exist_ok=force,parents=True)\n",
    "    api.dataset_initialize(dataset_path)\n",
    "    md = json.load(open(dataset_path/'dataset-metadata.json'))\n",
    "    md['title'] = title\n",
    "    md['id'] = md['id'].replace('INSERT_SLUG_HERE',title)\n",
    "    json.dump(md,open(dataset_path/'dataset-metadata.json','w'))\n",
    "    if upload: (dataset_path/'empty.txt').touch()\n",
    "    api.dataset_create_new(str(dataset_path),public=True,dir_mode='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data package template written to: testds/dataset-metadata.json\n"
     ]
    }
   ],
   "source": [
    "mk_dataset('./testds','mytestds',force=True)\n",
    "md = json.load(open('./testds/dataset-metadata.json'))\n",
    "assert md['title'] == 'mytestds'\n",
    "assert md['id'].endswith('/mytestds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_dataset(dataset_path, # Local path to download dataset to\n",
    "                dataset_slug, # Dataset slug (ie \"zillow/zecon\")\n",
    "                unzip=True, # Should it unzip after downloading?\n",
    "                force=False # Should it overwrite or error if dataset_path exists?\n",
    "               ):\n",
    "    '''Downloads an existing dataset and metadata from kaggle'''\n",
    "    if not force: assert not Path(dataset_path).exists()\n",
    "    api.dataset_metadata(dataset_slug,str(dataset_path))\n",
    "    api.dataset_download_files(dataset_slug,str(dataset_path))\n",
    "    if unzip:\n",
    "        zipped_file = Path(dataset_path)/f\"{dataset_slug.split('/')[-1]}.zip\"\n",
    "        import zipfile\n",
    "        with zipfile.ZipFile(zipped_file, 'r') as zip_ref:\n",
    "            zip_ref.extractall(Path(dataset_path))\n",
    "        zipped_file.unlink()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_path = Path('./mydataset')\n",
    "get_dataset(dl_path,'isaacflath/testds',force=True)\n",
    "ds_contents = ['abc.test','dataset-metadata.json','fastcore-1.5.11-py3-none-any.whl','packaging-21.3-py3-none-any.whl',\n",
    "               'pip-22.2.1-py3-none-any.whl','pyparsing-3.0.9-py3-none-any.whl']\n",
    "assert L(os.listdir(dl_path)).sorted() == ds_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_pip_library(dataset_path, # Local path to download pip library to\n",
    "                    pip_library, # name of library for pip to install\n",
    "                    pip_cmd=\"pip\" # pip base to use (ie \"pip3\" or \"pip\")\n",
    "                   ):    \n",
    "    '''Download the whl files for pip_library and store in dataset_path'''\n",
    "    bashCommand = f\"{pip_cmd} download {pip_library} -d {dataset_path}\"\n",
    "    process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_path = Path('./mylib')\n",
    "get_pip_library(dl_path,'fastkaggle')\n",
    "assert 1==len([o for o in dl_path.ls() if str(o).startswith(f\"{dl_path}/fastkaggle\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def push_dataset(dataset_path, # Local path where dataset is stored \n",
    "                 version_comment # Comment associated with this dataset update\n",
    "                ):\n",
    "    '''Push dataset update to kaggle.  Dataset path must contain dataset metadata file'''\n",
    "    api.dataset_create_version(str(dataset_path),version_comment,dir_mode='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path = Path('./testds452')\n",
    "# mk_dataset(dataset_path,'mytestd232s',force=True)\n",
    "# (dataset_path/'testfile.txt').touch()\n",
    "# push_dataset(dataset_path,'testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
