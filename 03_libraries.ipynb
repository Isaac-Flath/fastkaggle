{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fastkaggle.libraries\n",
    "\n",
    "> API details for fastkaggle libraries to help manage libraries as kaggle datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import os,json,subprocess, shutil\n",
    "import re\n",
    "from fastcore.utils import *\n",
    "\n",
    "from fastkaggle.core import *\n",
    "from fastkaggle.datasets import *\n",
    "from fastkaggle.competition import *\n",
    "# from fastcore.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pip Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_pip_library(pip_library, # name of library for pip to install\n",
    "                    cfg_path='.'\n",
    "                   ):    \n",
    "    '''Download the whl files for pip_library and store in dataset_path'''\n",
    "    cfg = get_config_values(cfg_path)\n",
    "    \n",
    "    pip_cmd=cfg['pip_cmd']\n",
    "    dataset_path = Path(cfg_path)/cfg['data_path']/pip_library\n",
    "\n",
    "    bashCommand = f\"{pip_cmd} download {pip_library} -d {dataset_path}\"\n",
    "    process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "    return process,output,error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = 'fastcore'\n",
    "get_pip_library(lib)\n",
    "assert Path(lib).exists()\n",
    "Path(lib).ls().map(lambda x: x.unlink())\n",
    "Path(lib).rmdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_pip_libraries(directory_name,\n",
    "                    cfg_path='.'\n",
    "                   ):    \n",
    "    cfg = get_config_values(cfg_path)\n",
    "    \n",
    "    pip_cmd=cfg['pip_cmd']\n",
    "    dataset_path = Path(cfg_path)/cfg['data_path']/directory_name\n",
    "    libraries = ' '.join(cfg['required_libraries'])\n",
    "\n",
    "    bashCommand = f\"{pip_cmd} download {libraries} -d {dataset_path}\"\n",
    "    process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "    return process,output,error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_name = 'my-test-libs'\n",
    "get_pip_libraries('my-test-libs')\n",
    "assert Path(directory_name).exists()\n",
    "Path(directory_name).ls().map(lambda x: x.unlink())\n",
    "Path(directory_name).rmdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_local_ds_ver(lib_path, # Local path dataset is stored in\n",
    "                     lib # Name of library (ie \"fastcore\")\n",
    "                    ):\n",
    "    '''checks a local copy of kaggle dataset for library version number'''\n",
    "    wheel_lib_name = lib.replace('-','_')\n",
    "    local_path = (lib_path/f\"library-{lib}\")\n",
    "    lib_whl = local_path.ls().filter(lambda x: wheel_lib_name in x.name.lower())\n",
    "    if 1==len(lib_whl):\n",
    "        return re.search(f\"(?<={wheel_lib_name}-)[\\d+.]+\\d\",lib_whl[0].name.lower())[0]\n",
    "    elif 0<len(local_path.ls().filter(lambda x: 'dist' in x.name)):\n",
    "        lib_whl = (local_path/'dist').ls().filter(lambda x: wheel_lib_name in x.name.lower())\n",
    "        if 1==len(lib_whl):\n",
    "            return re.search(f\"(?<={wheel_lib_name}-)[\\d+.]+\\d\",lib_whl[0].name.lower())[0]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_dependency_dataset(cfg_path='.', # Path to fastkaggle.json file\n",
    "                                version_notes = \"New Update\",\n",
    "                               ):\n",
    "    retain = [\"dataset-metadata.json\"],\n",
    "    cfg = get_config_values(cfg_path)\n",
    "    \n",
    "    pip_cmd=cfg['pip_cmd']\n",
    "    local_path = Path(cfg_path)/cfg['data_path']/cfg['libraries_dataset_name']\n",
    "    ds_slug = f\"{cfg['datasets_username']}/{cfg['libraries_dataset_name']}\"\n",
    "    \n",
    "    print(f\"-----Downloading or Creating Dataset if needed\")\n",
    "    if local_path.exists(): pass\n",
    "    elif ds_exists(ds_slug): get_dataset(ds_slug,str(local_path))\n",
    "    else:                    mk_dataset(local_path,cfg['libraries_dataset_name'])\n",
    "    \n",
    "    print(f\"-----Checking dataset files against pip\")\n",
    "    orig_ds = Path(local_path).ls().sorted()\n",
    "    for item in local_path.ls():\n",
    "        if item.name in retain: pass\n",
    "        elif item.is_dir(): shutil.rmtree(item)\n",
    "        else: item.unlink()        \n",
    "    get_pip_libraries(cfg['libraries_dataset_name'],cfg_path) \n",
    "    new_ds = Path(local_path).ls().sorted()\n",
    "    \n",
    "    if orig_ds != new_ds: \n",
    "        print(f\"-----Updating {cfg['libraries_dataset_name']} in Kaggle\")\n",
    "        push_dataset(local_path,version_notes)\n",
    "    else: print(f\"-----Kaggle dataset already up to date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Downloading or Creating Dataset if needed\n",
      "-----Checking dataset files against pip\n",
      "-----Updating libraries-titanic in Kaggle\n"
     ]
    }
   ],
   "source": [
    "create_dependency_dataset()\n",
    "path = Path('libraries-titanic')\n",
    "assert path.exists()\n",
    "assert ds_exists('isaacflath/libraries-titanic')\n",
    "ds_exists('isaacflath/libraries-titanic')\n",
    "Path(path).ls().map(lambda x: x.unlink())\n",
    "Path(path).rmdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
